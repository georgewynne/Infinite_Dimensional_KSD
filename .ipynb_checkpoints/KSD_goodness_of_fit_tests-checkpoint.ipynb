{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm_ntb\n",
    "from scipy.stats import multinomial\n",
    "from functools import partial\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KSD class if the main object used in the tests.\n",
    "\n",
    "It is calculated using a finite dimensional approximation of the data using the basis corresponding to the base Gaussian measure.\n",
    "\n",
    "For example, if we are considering functions over L^{2}([0,1]) and the base Gaussian measure is a Brownian motion. Then the basis is the standard Brownian basis e_{n}(t) = \\sqrt{2}\\sin((n-0.5)\\pi t)\n",
    "\n",
    "We approximate L^{2}([0,1]) inner products by <f,g> = \\sum_{n=1}^{\\infty}<f,e_{n}><g,e_{n}> \\approx \\sum_{n=1}^{n_freqs}<f,e_{n}><g,e_{n}> for some value n_freqs standing for number of frequencies.\n",
    "\n",
    "So the data one inputs into KSD is the n_freqs coefficients with respect to the Brownian motion basis.\n",
    "\n",
    "This is different from the projections used in functional data analysis which aim to use a low number of frequencies to represent signals, often no more than 12-15. Whereas we use a high number, n_freqs = 100 in our experiments, as it is purely a technique to make inner products easier to compute rather than for statistical efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSD Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_distance_mat(x1,y1,x2,y2,A,B = None):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Forms a distance matrix with ij-th entry <A(x1_i-y1_j),B(x2_i-y2_j)> where <.,.> is Euclidean inner product\n",
    "        and x_i = x[:,i] is i-th column of data, analogous for y_i. \n",
    "        If B = None then B becomes the identity.\n",
    "    Arg:\n",
    "        x1,x2: (d,n) matrix, data in columns\n",
    "        y1,y2: (d,m) matrix, data in columns\n",
    "        A: (d,d) matrix\n",
    "        B: (d,d) matrix\n",
    "    Return:\n",
    "        dist_mat: (n,m) matrix with ij-th entry <A(x1_i - y1_j), B(x2_i - y2_j)> \n",
    "                  where x1_i = x[:,i] is i-th data column, analogous for ,x2_i,y1_j,y2_j\n",
    "    \"\"\"  \n",
    "    d = x1.shape[0]\n",
    "    n = x1.shape[1]\n",
    "    m = y1.shape[1]\n",
    "    \n",
    "    if (B is None) or (B.all() is None):\n",
    "        B = np.eye(d)\n",
    "    \n",
    "    mat_x1x2 = np.einsum(\"ji,ji -> i\", A @ x1, B @ x2)\n",
    "    mat_x1x2 = np.reshape(mat_x1x2,(n,1))\n",
    "    mat_x1x2 = np.tile(mat_x1x2,(1,m))\n",
    "    \n",
    "    mat_y1y2 = np.einsum(\"ji,ji -> i\", A @ y1, B @ y2)\n",
    "    mat_y1y2 = np.reshape(mat_y1y2,(1,m))\n",
    "    mat_y1y2 = np.tile(mat_y1y2,(n,1))\n",
    "    \n",
    "    mat_x1y2 = np.einsum(\"ji,jk -> ik\",A @ x1, B @ y2)\n",
    "    mat_y1x2 = np.einsum(\"jk,ji -> ik\",A @ y1, B @ x2)\n",
    "    \n",
    "    dist_mat = mat_x1x2 + mat_y1y2 - mat_x1y2 - mat_y1x2\n",
    "    \n",
    "    return dist_mat\n",
    "\n",
    "class KSD:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Class to represent an instance of kernel Stein discrepancy.\n",
    "        Has methods to ouput the Stein kernel evaluated on data\n",
    "    \"\"\"  \n",
    "    def __init__(self,C,T,DU = 0,kernel_type = \"SE\", gamma = -1):\n",
    "        \"\"\"\n",
    "        Arg:\n",
    "            C: (d,d) matrix representing the covariance operator\n",
    "            T: (d,d) matrix representing the hyperparameter\n",
    "            DU: Function for the DU term in KSD. Default is DU = 0 which makes the DU term be 0.\n",
    "            kernel_type: either \"SE\" or \"IMQ\"\n",
    "            gamma: lengthscale, if -1 then median heuristic is employed\n",
    "        \"\"\"  \n",
    "        self.C = C\n",
    "        self.T = T\n",
    "        self.DU = DU\n",
    "        self.kernel_type = kernel_type\n",
    "        self.gamma = gamma\n",
    "        \n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        \"\"\"\n",
    "        Arg:\n",
    "            x: (d,n) data matrix\n",
    "            y: (d,m) data matrix\n",
    "        Return:\n",
    "            Stein_mat: (n,m) matrix with ij-th entry the Stein kernel h evaluated at x_i,y_j \n",
    "        \"\"\"\n",
    "\n",
    "        n = np.shape(x)[1]\n",
    "        m = np.shape(y)[1] \n",
    "        \n",
    "        sqr_dist_mat = form_distance_mat(x,y,x,y,T,T)\n",
    "            \n",
    "        # median heuristic\n",
    "        if self.gamma == -1:\n",
    "            self.gamma = np.sqrt(np.median(sqr_dist_mat[sqr_dist_mat > 0]))\n",
    "            # changes the T which will be used later\n",
    "            self.T = self.T/self.gamma\n",
    "            # renormalises the squared distance matrix already computed that'll be used later\n",
    "            sqr_dist_mat = sqr_dist_mat/(self.gamma**2)\n",
    "        \n",
    "        # introduces variable S to make calculations easier\n",
    "        S = self.C @ np.transpose(self.T) @ self.T\n",
    "        # form the CDU terms\n",
    "        if self.DU == 0:\n",
    "            CDUx = np.zeros(np.shape(x))\n",
    "            CDUy = np.zeros(np.shape(y))\n",
    "        else:\n",
    "            CDUx = C @ self.DU(x)\n",
    "            CDUy = C @ self.DU(y)\n",
    "        \n",
    "        # <x + CDU(x),y+CDU(y)> term\n",
    "        term1 = np.einsum(\"ji,jk -> ik\",x+CDUx,y + CDUy)\n",
    "        # - <S(x-y),x-y> term\n",
    "        term2 = -1 * form_distance_mat(x,y,x,y,S)\n",
    "        # - <S(x-y),CDU(x)-CDU(y)> term\n",
    "        term3 = -1 * form_distance_mat(x,y,CDUx,CDUy,S)\n",
    "        # Tr(SC) term\n",
    "        term4 = np.trace(S @ C)\n",
    "        # ||S(x-y)||^2 term\n",
    "        term5 = -1 * form_distance_mat(x,y,x,y,S,S)\n",
    "    \n",
    "        # calculations are taken from example of Stein kernels in paper associated with SE and IMQ base kernels\n",
    "        if self.kernel_type == \"SE\":\n",
    "            \n",
    "            SE_mat = np.exp(-0.5 * sqr_dist_mat)\n",
    "            \n",
    "            Stein_mat = SE_mat * (term1 + term2 + term3 + term4 + term5)\n",
    "            \n",
    "            return Stein_mat\n",
    "        \n",
    "        if self.kernel_type == \"IMQ\":\n",
    "            \n",
    "            IMQ_mat = (sqr_dist_mat + 1)**(-0.5)\n",
    "            \n",
    "            Stein_mat = (term1 * IMQ_mat)  + ((term2 + term3 + term4) * (IMQ_mat**3)) + (3 * term5 * (IMQ_mat**5))\n",
    "            \n",
    "            return Stein_mat\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodnessOfFitTest:\n",
    "    \"\"\"\n",
    "    Description: A single goodness-of-fit test which can produce a p-value given data and a KSD object\n",
    "    \"\"\"\n",
    "    def __init__(self, discrepancy, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            discrepancy: A callable that returns a matrix of Stein kernel evaluations\n",
    "            x: (d,n) matrix of data\n",
    "        \"\"\"\n",
    "        self.d = discrepancy\n",
    "        self.x = x\n",
    "        self.n = x.shape[1]\n",
    "        \n",
    "\n",
    "    def compute_pvalue(self, nbootstrap):\n",
    "        \"\"\"\n",
    "        Arg:\n",
    "            nbootstrap: Number of bootstrap samples.\n",
    "        Return:\n",
    "            bootstrap_stats: bootstraped test statistics\n",
    "            test_stat: the test statistic calculated using observed data\n",
    "            pvalue: p-value based on comparing test_stat with bootstrap_stats\n",
    "        \"\"\"\n",
    "        # Form the test statistic from evaluations of the Stein kernel\n",
    "        stein_matrix = self.d(self.x, self.x)\n",
    "        u_matrix = stein_matrix - np.diag(np.diag(stein_matrix))\n",
    "        test_stat = u_matrix.sum() / self.n / (self.n-1)\n",
    "        \n",
    "        # Obtain bootstrap samples using multi-nomial distribution\n",
    "        bootstrap_stats = np.zeros(n_bootstrap)\n",
    "        for i in range(n_bootstrap):\n",
    "            W = np.random.multinomial(self.n,(1./self.n)*np.ones(self.n))\n",
    "            W = (W-1)/self.n\n",
    "            bootstrap_stats[i] = W @ u_matrix @ W\n",
    "        \n",
    "        # Calculate p-value\n",
    "        pvalue = (bootstrap_stats > test_stat).mean()\n",
    "\n",
    "        return (bootstrap_stats, test_stat, pvalue)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brownian target experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each experiment we need a sampler that provides the data. \n",
    "\n",
    "As our implementation requires data projected to the basis of the base Gaussian the samplers will simulate the trajectories and then projecct to n_freqs basis elements of Brownian motion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brownian motion basis used to project data onto\n",
    "def BM_basis(n_freqs,obs):\n",
    "    X = np.zeros((n_freqs,len(obs)))\n",
    "    for i in range(1,n_freqs+1):\n",
    "        X[i-1,:] = np.sqrt(2)*np.sin((i-0.5)*np.pi*obs)\n",
    "    return X\n",
    "\n",
    "# Generates Ornstein-Uhlenbeck trajectories\n",
    "def OU_sampler(N,grid_size,theta,mu=5,random_state = None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    dt = 1/grid_size\n",
    "    X = np.zeros((N,grid_size))\n",
    "    noise = rng.randn(N,grid_size)*np.sqrt(dt)\n",
    "    for i in range(1,grid_size):\n",
    "        X[:,i] = X[:,i-1] + theta*(mu-X[:,i-1])*dt + noise[:,i]\n",
    "    return X\n",
    "\n",
    "# Generates Brownian motion clipped to certain a frequency\n",
    "# Since the samples are computed using random variables against BM basis elements\n",
    "# and we only use the coefficients in the computation of KSD, we can simulate \n",
    "# this data by simply simulating the random variable coefficients\n",
    "def BM_clip(N,n_freqs,clip_freq,grid_size = 100,random_state = None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    C = np.zeros(n_freqs)\n",
    "    lambda_diag = np.array([1/(np.pi * (n-0.5))**2 for n in range(1,clip_freq + 1)])\n",
    "    C[:clip_freq] = lambda_diag\n",
    "    coefs = rng.multivariate_normal(mean = np.zeros(n_freqs),cov = np.diag(C),size = N)\n",
    "    return coefs.T\n",
    "\n",
    "# Generates OU trajectories projected to a specified number of frequencies of Brownian motion basis\n",
    "def OU_freqs_sampler(N,n_freqs,theta,mu=5,sig=1,random_state = None):\n",
    "    grid_size = 100\n",
    "    obs = np.linspace(0,1,grid_size,endpoint=True)\n",
    "    basis = BM_basis(n_freqs,obs)\n",
    "    OU_vals = OU_sampler(N,grid_size,theta,mu,random_state)\n",
    "    return (1/grid_size)*np.dot(OU_vals,basis.T).T\n",
    "\n",
    "# Generates samples from the referenced Cuesta-Albertos et al 2007 paper\n",
    "def CA_sampler(N,grid_size,a_1,a_2,a_3,random_state = None):\n",
    "    BM_arr = OU_sampler(N,grid_size,theta=0,mu=0,random_state=random_state)\n",
    "    obs = np.linspace(0,1,grid_size,endpoint=False)\n",
    "    det_arr = 1 + a_1*(obs**2) + a_2*np.sin(2*np.pi*obs) + a_3*np.exp(obs)\n",
    "    return BM_arr * det_arr\n",
    "\n",
    "# Generates trajectories from CA_sampler projected to a specified number of frequencies of Brownian motion basis\n",
    "def CA_freqs_sampler(N,n_freqs,a_1,a_2,a_3,random_state = None):\n",
    "    grid_size = 100\n",
    "    basis = BM_basis(n_freqs,np.linspace(0,1,grid_size,endpoint=False))\n",
    "    AC_vals = CA_sampler(N,grid_size,a_1,a_2,a_3,random_state = random_state)\n",
    "    return (1/grid_size)*np.dot(AC_vals,basis.T).T\n",
    "\n",
    "# Generates trajectories from Ditzhaus and Gaigall 2018 referenced paper projected to a specified number of frequencies of Brownian motion basis\n",
    "def Ditzhaus_freqs_sampler(N,n_freqs=100,a=1,b=0,random_state = None):\n",
    "    grid_size = 100\n",
    "    X = a*OU_sampler(N,grid_size,theta = 0,random_state=random_state)\n",
    "    obs = np.linspace(0,1,grid_size,endpoint=False)\n",
    "    X += b*obs*(obs-1)\n",
    "    basis = BM_basis(n_freqs,np.linspace(0,1,grid_size,endpoint=False))\n",
    "    return (1/grid_size)*np.dot(X,basis.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of frequencies to use in numerical approximation of inner products\n",
    "# Here we use 100 meaning we are working in the space spanned by the first\n",
    "# 100 basis functions of Brownian motion\n",
    "n_freqs = 100\n",
    "\n",
    "# Set the target covariance operator in matrix form with respect to \n",
    "# the specified number of basis elements, these are the eigenvalues \n",
    "# of Brownian motion decomposition\n",
    "C = np.diag([(1/((i-0.5)*np.pi))**(2) for i in np.arange(1,n_freqs+1)])\n",
    "\n",
    "# Set hyperparameters\n",
    "T_1 = np.eye(n_freqs)\n",
    "n_adjust_freqs = 50\n",
    "T_2 = np.eye(n_freqs)\n",
    "T_2[np.diag_indices(n_adjust_freqs)] = C[np.diag_indices(n_adjust_freqs)]**(-1)\n",
    "\n",
    "# Set median heuristic, -1 is used as a flag in the KSD to employ median heuristic\n",
    "gamma = -1\n",
    "\n",
    "# Set test specification\n",
    "n_tests = 500\n",
    "n_bootstrap = 2000\n",
    "\n",
    "# Set random seed\n",
    "rng_X = 1234\n",
    "\n",
    "# Store kernel and hyperparameter specifications\n",
    "kernel_list = [\"SE\",\"IMQ\"]\n",
    "T_list = [T_1,T_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment which ever experiment it is you want to run\n",
    "\n",
    "# Experiment 1\n",
    "n_samples = 50\n",
    "sampler = partial(BM_clip,n_freqs = n_freqs,clip_freq = n_freqs,random_state = rng_X)\n",
    "\n",
    "# Experiment 2:\n",
    "# n_samples = 50\n",
    "# sampler = partial(BM_clip,n_freqs = n_freqs,clip_freq = 5,random_state = rng_X)\n",
    "\n",
    "# Experimen 3: \n",
    "# n_samples = 25\n",
    "# sampler = partial(OU_freqs_sampler,n_freqs = n_freqs,theta = 0.5,mu=5,random_state = rng_X)\n",
    "\n",
    "# Experiment 4:\n",
    "# n_samples = 50\n",
    "# sampler = partial(CA_freqs_sampler,n_freqs = n_freqs,a_1=1,a_2=0,a_3=0,random_state = rng_X)\n",
    "\n",
    "# Experiment 5:\n",
    "# n_samples = 50\n",
    "# sampler = partial(CA_freqs_sampler,n_freqs = n_freqs,a_1=0,a_2=1,a_3=0,random_state = rng_X)\n",
    "\n",
    "# Experiment 6:\n",
    "# n_samples = 25\n",
    "# sampler = partial(Ditzhaus_freqs_sampler,n_freqs = n_freqs,a=2,b=0,random_state = rng_X)\n",
    "\n",
    "# Experiment 7:\n",
    "# n_samples = 25\n",
    "# sampler = partial(Ditzhaus_freqs_sampler,n_freqs = n_freqs,a=1,b=1.5,random_state = rng_X)\n",
    "\n",
    "\n",
    "# We samples n_samples * n_tests many samples so we have neough samples for all the tests \n",
    "# performed to calculate power\n",
    "test_data = sampler(n_samples*n_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for kernel in kernel_list:\n",
    "    for i in range(len(T_list)):\n",
    "        T = T_list[i]\n",
    "        rej = 0\n",
    "        for t in tqdm_ntb(range(n_tests)):\n",
    "            my_KSD = KSD(C,T,kernel_type = kernel)\n",
    "            data = test_data[:,t*n_samples:(t+1)*n_samples]\n",
    "            single_test = GoodnessOfFitTest(my_KSD,data)\n",
    "            _,_,pvalue = single_test.compute_pvalue(n_bootstrap)\n",
    "            rej += (pvalue < 0.05)\n",
    "        print(kernel,\" with T_\", i+1, \" n_samples \", n_samples, \"has power \",rej/n_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs target experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next experiments use the Brownian bridge as the base Gauss measure.\n",
    "\n",
    "The samples from the true distribution are obtained using a PDMP sampler, see the other notebook for the code to generate these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_basis(n_freqs,obs,TT):\n",
    "    X = np.zeros((n_freqs,len(obs)))\n",
    "    for i in range(1,n_freqs+1):\n",
    "        X[i-1,:] = (np.sqrt(2) / np.sqrt(TT)) * np.sin(i*np.pi*obs/TT)\n",
    "    return X\n",
    "\n",
    "def sin_DU(x,obs, TT = 50.0):\n",
    "    alpha = 0.7\n",
    "    dim = np.shape(x)[0]\n",
    "    x_recon = np.dot(BB_basis(dim,obs,TT).T,x)\n",
    "    DUx = ((alpha**2) * np.sin(x_recon)*np.cos(x_recon)) - ((alpha / 2)*np.sin(x_recon))\n",
    "    DUx_freqs = (TT/len(obs))*np.dot(BB_basis(dim,obs,TT),DUx)\n",
    "    return DUx_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of frequencies to use in numerical approximation of inner products\n",
    "# Here we use 100 meaning we are working in the space spanned by the first\n",
    "# 100 basis functions of Brownian bridge\n",
    "n_freqs = 100\n",
    "\n",
    "# TT denotes the end of the time interval the SDEs are ran over\n",
    "TT = 50.0\n",
    "\n",
    "# Set the target covariance operator in matrix form with respect to \n",
    "# the specified number of basis elements, these are the eigenvalues \n",
    "# of Brownian bridge decomposition\n",
    "C = np.diag([(1/(i*np.pi/TT))**(2) for i in np.arange(1,n_freqs + 1)])\n",
    "\n",
    "# Set hyperparameters\n",
    "T_1 = np.eye(n_freqs)\n",
    "n_adjust_freqs = 50\n",
    "T_2 = np.eye(n_freqs)\n",
    "T_2[np.diag_indices(n_adjust_freqs)] = C[np.diag_indices(n_adjust_freqs)]**(-1)\n",
    "\n",
    "# Set median heuristic\n",
    "gamma = -1\n",
    "\n",
    "# Set test specification\n",
    "n_tests = 100\n",
    "n_bootstrap = 2000\n",
    "n_samples = 100\n",
    "\n",
    "# Set random seed\n",
    "rng_X = 1234\n",
    "\n",
    "# Store kernel and hyperparameter specifications\n",
    "kernel_list = [\"SE\",\"IMQ\"]\n",
    "T_list = [T_1,T_2]\n",
    "\n",
    "# Create the function for evaluating DU used in KSD class\n",
    "# This is the grid used in the PDMP simulation of the paths \n",
    "obs = np.linspace(0,TT,129,endpoint=True)\n",
    "sin_DU_partial = partial(sin_DU,obs = obs, TT = TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDMP_paths = np.load(\"PDMP_paths.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data to remove dependence from the samples as a result of the PDMP sampler\n",
    "PDMP_paths = PDMP_paths.T\n",
    "rng_shuffle = np.random.RandomState(1234)\n",
    "rng_shuffle.shuffle(PDMP_paths)\n",
    "PDMP_paths = PDMP_paths.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set deviation from null\n",
    "delta = 0\n",
    "PDMP_paths_delta = PDMP_paths +  (delta * (obs/TT)[:,None])\n",
    "\n",
    "# Compute the frequency representation to be used in the KSD class\n",
    "PDMP_freqs = (TT/len(obs))*np.dot(BB_basis(n_freqs,obs,TT),PDMP_paths_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for kernel in kernel_list:\n",
    "    for i in np.arange(len(T_list)):\n",
    "        T = T_list[i]\n",
    "        rej = 0\n",
    "        for t in tqdm_ntb(range(n_tests)):\n",
    "            my_KSD = KSD(C,T,DU = sin_DU_partial,kernel_type = kernel)\n",
    "            data = PDMP_freqs[:,t*n_samples:(t+1)*n_samples]\n",
    "            single_test = GoodnessOfFitTest(my_KSD,data)\n",
    "            _,_,pvalue = single_test.compute_pvalue(n_bootstrap)\n",
    "            rej += (pvalue < 0.05)\n",
    "        print(kernel,\" with T_\", i+1, \" n_samples \", n_samples, \" has power \",rej/n_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
