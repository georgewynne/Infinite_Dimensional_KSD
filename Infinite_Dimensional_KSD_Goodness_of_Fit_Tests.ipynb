{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code used to perform goodness of fit tests for functional data using KSD. The main part of this code ids the KSD class which facilitates the KSD computations. \n",
    "\n",
    "The data used for the tests is either generated using functions in this notebook or other notebooks inn the repository which build upon more advanced samplers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm_ntb\n",
    "from scipy.stats import multinomial\n",
    "from functools import partial\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KSD class if the main object used in the tests.\n",
    "\n",
    "It is calculated using a finite dimensional approximation of the data using the basis corresponding to the base Gaussian measure.\n",
    "\n",
    "For example, if we are considering functions over L^{2}([0,1]) and the base Gaussian measure is a Brownian motion. Then the basis is the standard Brownian basis e_{n}(t) = \\sqrt{2}\\sin((n-0.5)\\pi t)\n",
    "\n",
    "We approximate L^{2} inner products by <f,g> = \\sum_{n=1}^{\\infty}<f,e_{n}><g,e_{n}> \\approx \\sum_{n=1}^{n_freqs}<f,e_{n}><g,e_{n}> for some value n_freqs standing for number of frequencies.\n",
    "\n",
    "So the data one inputs into KSD is the n_freqs coefficients with respect to a basis.\n",
    "\n",
    "This is different from the projections used in functional data analysis which aim to use a low number of frequencies to represent signals, often no more than 12-15. Whereas we use a high number, n_freqs = 100 in our experiments, as it is purely a technique to make inner products easier to compute rather than for statistical efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSD Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_distance_mat(x1,y1,x2,y2,A,B = None):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Forms a distance matrix with ij-th entry <A(x1_i-y1_j),B(x2_i-y2_j)> where <.,.> is Euclidean inner product\n",
    "        and x_i = x[:,i] is i-th column of data, analogous for y_i. \n",
    "        If B = None then B becomes the identity.\n",
    "    Arg:\n",
    "        x1,x2: (d,n) matrix, data in columns\n",
    "        y1,y2: (d,m) matrix, data in columns\n",
    "        A: (d,d) matrix\n",
    "        B: (d,d) matrix\n",
    "    Return:\n",
    "        dist_mat: (n,m) matrix with ij-th entry <A(x1_i - y1_j), B(x2_i - y2_j)> \n",
    "                  where x1_i = x[:,i] is i-th data column, analogous for ,x2_i,y1_j,y2_j\n",
    "    \"\"\"  \n",
    "    d = x1.shape[0]\n",
    "    n = x1.shape[1]\n",
    "    m = y1.shape[1]\n",
    "    \n",
    "    if (B is None) or (B.all() is None):\n",
    "        B = np.eye(d)\n",
    "    \n",
    "    mat_x1x2 = np.einsum(\"ji,ji -> i\", A @ x1, B @ x2)\n",
    "    mat_x1x2 = np.reshape(mat_x1x2,(n,1))\n",
    "    mat_x1x2 = np.tile(mat_x1x2,(1,m))\n",
    "    \n",
    "    mat_y1y2 = np.einsum(\"ji,ji -> i\", A @ y1, B @ y2)\n",
    "    mat_y1y2 = np.reshape(mat_y1y2,(1,m))\n",
    "    mat_y1y2 = np.tile(mat_y1y2,(n,1))\n",
    "    \n",
    "    mat_x1y2 = np.einsum(\"ji,jk -> ik\",A @ x1, B @ y2)\n",
    "    mat_y1x2 = np.einsum(\"jk,ji -> ik\",A @ y1, B @ x2)\n",
    "    \n",
    "    dist_mat = mat_x1x2 + mat_y1y2 - mat_x1y2 - mat_y1x2\n",
    "    \n",
    "    return dist_mat\n",
    "\n",
    "class KSD:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Class to represent an instance of kernel Stein discrepancy.\n",
    "        Has methods to ouput the Stein kernel evaluated on data\n",
    "    \"\"\"  \n",
    "    def __init__(self,C,T,DU = 0,kernel_type = \"SE\", gamma = -1):\n",
    "        \"\"\"\n",
    "        Arg:\n",
    "            C: (d,d) matrix representing the covariance operator\n",
    "            T: (d,d) matrix representing the hyperparameter\n",
    "            DU: Function for the DU term in KSD. Default is DU = 0 which makes the DU term be 0.\n",
    "            kernel_type: either \"SE\" or \"IMQ\"\n",
    "            gamma: lengthscale, if -1 then median heuristic is employed\n",
    "        \"\"\"  \n",
    "        self.C = C\n",
    "        self.T = T\n",
    "        self.DU = DU\n",
    "        self.kernel_type = kernel_type\n",
    "        self.gamma = gamma\n",
    "        \n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        \"\"\"\n",
    "        Arg:\n",
    "            x: (d,n) data matrix\n",
    "            y: (d,m) data matrix\n",
    "        Return:\n",
    "            Stein_mat: (n,m) matrix with ij-th entry the Stein kernel h evaluated at x_i,y_j \n",
    "        \"\"\"\n",
    "\n",
    "        n = np.shape(x)[1]\n",
    "        m = np.shape(y)[1] \n",
    "        \n",
    "        sqr_dist_mat = form_distance_mat(x,y,x,y,T,T)\n",
    "            \n",
    "        # median heuristic\n",
    "        if self.gamma == -1:\n",
    "            self.gamma = np.sqrt(np.median(sqr_dist_mat[sqr_dist_mat > 0]))\n",
    "            #print(self.gamma)\n",
    "            # changes the T which will be used later\n",
    "            self.T = self.T/self.gamma\n",
    "            # renormalises the squared distance matrix already computed that'll be used later\n",
    "            sqr_dist_mat = sqr_dist_mat/(self.gamma**2)\n",
    "        \n",
    "        # introduces variable S to make calculations easier\n",
    "        S = self.C @ np.transpose(self.T) @ self.T\n",
    "        # form the CDU terms\n",
    "        if self.DU == 0:\n",
    "            CDUx = np.zeros(np.shape(x))\n",
    "            CDUy = np.zeros(np.shape(y))\n",
    "        else:\n",
    "            CDUx = C @ self.DU(x)\n",
    "            CDUy = C @ self.DU(y)\n",
    "        \n",
    "        # <x + CDU(x),y+CDU(y)> term\n",
    "        term1 = np.einsum(\"ji,jk -> ik\",x+CDUx,y + CDUy)\n",
    "        # - <S(x-y),x-y> term\n",
    "        term2 = -1 * form_distance_mat(x,y,x,y,S)\n",
    "        # - <S(x-y),CDU(x)-CDU(y)> term\n",
    "        term3 = -1 * form_distance_mat(x,y,CDUx,CDUy,S)\n",
    "        # Tr(SC) term\n",
    "        term4 = np.trace(S @ C)\n",
    "        # ||S(x-y)||^2 term\n",
    "        term5 = -1 * form_distance_mat(x,y,x,y,S,S)\n",
    "    \n",
    "        # calculations are taken from example of Stein kernels in paper associated with SE and IMQ base kernels\n",
    "        if self.kernel_type == \"SE\":\n",
    "            \n",
    "            SE_mat = np.exp(-0.5 * sqr_dist_mat)\n",
    "            \n",
    "            Stein_mat = SE_mat * (term1 + term2 + term3 + term4 + term5)\n",
    "            \n",
    "            return Stein_mat\n",
    "        \n",
    "        if self.kernel_type == \"IMQ\":\n",
    "            \n",
    "            IMQ_mat = (sqr_dist_mat + 1)**(-0.5)\n",
    "            \n",
    "            Stein_mat = (term1 * IMQ_mat)  + ((term2 + term3 + term4) * (IMQ_mat**3)) + (3 * term5 * (IMQ_mat**5))\n",
    "            \n",
    "            return Stein_mat\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodnessOfFitTest:\n",
    "    \"\"\"\n",
    "    Description: A single goodness-of-fit test which can produce a p-value given data and a KSD object\n",
    "    \"\"\"\n",
    "    def __init__(self, discrepancy, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            discrepancy: A callable that returns a matrix of Stein kernel evaluations\n",
    "            x: (d,n) matrix of data\n",
    "        \"\"\"\n",
    "        self.d = discrepancy\n",
    "        self.x = x\n",
    "        self.n = x.shape[1]\n",
    "        \n",
    "\n",
    "    def compute_pvalue(self, nbootstrap):\n",
    "        \"\"\"\n",
    "        Arg:\n",
    "            nbootstrap: Number of bootstrap samples.\n",
    "        Return:\n",
    "            bootstrap_stats: bootstraped test statistics\n",
    "            test_stat: the test statistic calculated using observed data\n",
    "            pvalue: p-value based on comparing test_stat with bootstrap_stats\n",
    "        \"\"\"\n",
    "        # Form the test statistic from evaluations of the Stein kernel\n",
    "        stein_matrix = self.d(self.x, self.x)\n",
    "        u_matrix = stein_matrix - np.diag(np.diag(stein_matrix))\n",
    "        test_stat = u_matrix.sum() / self.n / (self.n-1)\n",
    "        \n",
    "        # Obtain bootstrap samples using multi-nomial distribution\n",
    "        bootstrap_stats = np.zeros(n_bootstrap)\n",
    "        for i in range(n_bootstrap):\n",
    "            W = np.random.multinomial(self.n,(1./self.n)*np.ones(self.n))\n",
    "            W = (W-1)/self.n\n",
    "            bootstrap_stats[i] = W @ u_matrix @ W\n",
    "        \n",
    "        # Calculate p-value\n",
    "        pvalue = (bootstrap_stats > test_stat).mean()\n",
    "\n",
    "        return (bootstrap_stats, test_stat, pvalue)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brownian goodness-of-fit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each experiment we need a sampler that provides the data. \n",
    "\n",
    "As our implementation requires data projected to the basis of the base Gaussian the samplers will simulate the trajectories and then projecct to n_freqs basis elements of Brownian motion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brownian motion basis used to project data onto\n",
    "def BM_basis(n_freqs,obs):\n",
    "    X = np.zeros((n_freqs,len(obs)))\n",
    "    for i in range(1,n_freqs+1):\n",
    "        X[i-1,:] = np.sqrt(2)*np.sin((i-0.5)*np.pi*obs)\n",
    "    return X\n",
    "\n",
    "# Generates Ornstein-Uhlenbeck trajectories\n",
    "def OU_sampler(N,grid_size,theta,mu=5,random_state = None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    dt = 1/grid_size\n",
    "    X = np.zeros((N,grid_size))\n",
    "    noise = rng.randn(N,grid_size)*np.sqrt(dt)\n",
    "    for i in range(1,grid_size):\n",
    "        X[:,i] = X[:,i-1] + theta*(mu-X[:,i-1])*dt + noise[:,i]\n",
    "    return X\n",
    "\n",
    "# Generates Brownian motion clipped to certain a frequency\n",
    "# Since the samples are computed using random variables against BM basis elements\n",
    "# and we only use the coefficients in the computation of KSD, we can simulate \n",
    "# this data by simply simulating the random variable coefficients\n",
    "def BM_clip(N,n_freqs,clip_freq,grid_size = 100,random_state = None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    C = np.zeros(n_freqs)\n",
    "    lambda_diag = np.array([1/(np.pi * (n-0.5))**2 for n in range(1,clip_freq + 1)])\n",
    "    C[:clip_freq] = lambda_diag\n",
    "    coefs = rng.multivariate_normal(mean = np.zeros(n_freqs),cov = np.diag(C),size = N)\n",
    "    return coefs.T\n",
    "\n",
    "# Generates OU trajectories projected to a specified number of frequencies of Brownian motion basis\n",
    "def OU_freqs_sampler(N,n_freqs,theta,mu=5,sig=1,random_state = None):\n",
    "    grid_size = 100\n",
    "    obs = np.linspace(0,1,grid_size,endpoint=True)\n",
    "    basis = BM_basis(n_freqs,obs)\n",
    "    OU_vals = OU_sampler(N,grid_size,theta,mu,random_state)\n",
    "    return (1/grid_size)*np.dot(OU_vals,basis.T).T\n",
    "\n",
    "# Generates samples from the referenced Cuesta-Albertos et al 2007 paper\n",
    "def CA_sampler(N,grid_size,a_1,a_2,a_3,random_state = None):\n",
    "    BM_arr = OU_sampler(N,grid_size,theta=0,mu=0,random_state=random_state)\n",
    "    obs = np.linspace(0,1,grid_size,endpoint=False)\n",
    "    det_arr = 1 + a_1*(obs**2) + a_2*np.sin(2*np.pi*obs) + a_3*np.exp(obs)\n",
    "    return BM_arr * det_arr\n",
    "\n",
    "# Generates trajectories from CA_sampler projected to a specified number of frequencies of Brownian motion basis\n",
    "def CA_freqs_sampler(N,n_freqs,a_1,a_2,a_3,random_state = None):\n",
    "    grid_size = 100\n",
    "    basis = BM_basis(n_freqs,np.linspace(0,1,grid_size,endpoint=False))\n",
    "    AC_vals = CA_sampler(N,grid_size,a_1,a_2,a_3,random_state = random_state)\n",
    "    return (1/grid_size)*np.dot(AC_vals,basis.T).T\n",
    "\n",
    "# Generates trajectories from Ditzhaus and Gaigall 2018 referenced paper projected to a specified number of frequencies of Brownian motion basis\n",
    "def Ditzhaus_freqs_sampler(N,n_freqs=100,a=1,b=0,random_state = None):\n",
    "    grid_size = 100\n",
    "    X = a*OU_sampler(N,grid_size,theta = 0,random_state=random_state)\n",
    "    obs = np.linspace(0,1,grid_size,endpoint=False)\n",
    "    X += b*obs*(obs-1)\n",
    "    basis = BM_basis(n_freqs,np.linspace(0,1,grid_size,endpoint=False))\n",
    "    return (1/grid_size)*np.dot(X,basis.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of frequencies to use in numerical approximation of inner products\n",
    "# Here we use 100 meaning we are working in the space spanned by the first\n",
    "# 100 basis functions of Brownian motion\n",
    "n_freqs = 100\n",
    "\n",
    "# Set the target covariance operator in matrix form with respect to \n",
    "# the specified number of basis elements, these are the eigenvalues \n",
    "# of Brownian motion decomposition\n",
    "C = np.diag([(1/((i-0.5)*np.pi))**(2) for i in np.arange(1,n_freqs+1)])\n",
    "\n",
    "# Set hyperparameters\n",
    "T_1 = np.eye(n_freqs)\n",
    "n_adjust_freqs = 50\n",
    "T_2 = np.eye(n_freqs)\n",
    "T_2[np.diag_indices(n_adjust_freqs)] = C[np.diag_indices(n_adjust_freqs)]**(-1)\n",
    "\n",
    "# Set median heuristic\n",
    "gamma = -1\n",
    "\n",
    "# Set test specification\n",
    "n_tests = 500\n",
    "n_bootstrap = 2000\n",
    "\n",
    "# Set random seed\n",
    "rng_X = 1234\n",
    "\n",
    "# Store kernel and hyperparameter specifications\n",
    "kernel_list = [\"SE\",\"IMQ\"]\n",
    "T_list = [T_1,T_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment which ever experiment it is you want to run\n",
    "\n",
    "# Experiment 1\n",
    "n_samples = 50\n",
    "sampler = partial(BM_clip,n_freqs = n_freqs,clip_freq = n_freqs,random_state = rng_X)\n",
    "\n",
    "# Experiment 2:\n",
    "# n_samples = 50\n",
    "# sampler = partial(BM_clip,n_freqs = n_freqs,clip_freq = 5,random_state = rng_X)\n",
    "\n",
    "# Experimen 3: \n",
    "# n_samples = 25\n",
    "# sampler = partial(OU_freqs_sampler,n_freqs = n_freqs,theta = 0.5,mu=5,random_state = rng_X)\n",
    "\n",
    "# Experiment 4:\n",
    "# n_samples = 50\n",
    "# sampler = partial(CA_freqs_sampler,n_freqs = n_freqs,a_1=1,a_2=0,a_3=0,random_state = rng_X)\n",
    "\n",
    "# Experiment 5:\n",
    "# n_samples = 50\n",
    "# sampler = partial(CA_freqs_sampler,n_freqs = n_freqs,a_1=0,a_2=1,a_3=0,random_state = rng_X)\n",
    "\n",
    "# Experiment 6:\n",
    "# n_samples = 25\n",
    "# sampler = partial(Ditzhaus_freqs_sampler,n_freqs = n_freqs,a=2,b=0,random_state = rng_X)\n",
    "\n",
    "# Experiment 7:\n",
    "# n_samples = 25\n",
    "# sampler = partial(Ditzhaus_freqs_sampler,n_freqs = n_freqs,a=1,b=1.5,random_state = rng_X)\n",
    "\n",
    "\n",
    "# We samples n_samples * n_tests many samples so we have neough samples for all the tests \n",
    "# performed to calculate power\n",
    "test_data = sampler(n_samples*n_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw1018/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66451352a12d46388d11a3dc53343776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE  with T_ 1  n_samples  25 has power  0.526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9edffdc66664c4ab5c8fd83a1c1dbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE  with T_ 2  n_samples  25 has power  0.99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b60ad62b734e08bb51e571724e729d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMQ  with T_ 1  n_samples  25 has power  0.618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159f128769354c458f49bdf9afdbbd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMQ  with T_ 2  n_samples  25 has power  0.868\n"
     ]
    }
   ],
   "source": [
    "for kernel in kernel_list:\n",
    "    for i in range(len(T_list)):\n",
    "        T = T_list[i]\n",
    "        rej = 0\n",
    "        for t in tqdm_ntb(range(n_tests)):\n",
    "            my_KSD = KSD(C,T,kernel_type = kernel)\n",
    "            data = test_data[:,t*n_samples:(t+1)*n_samples]\n",
    "            single_test = GoodnessOfFitTest(my_KSD,data)\n",
    "            _,_,pvalue = single_test.compute_pvalue(n_bootstrap)\n",
    "            rej += (pvalue < 0.05)\n",
    "        print(kernel,\" with T_\", i+1, \" n_samples \", n_samples, \"has power \",rej/n_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs goodness-of-fit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells perform a goodness-of-fit test for Gibbs measures.\n",
    "\n",
    "These cells are used in the paper to perform the goodness-of-fit tests where either the samples are perturbed by a mean function, or the samples are being taken over a larger terminal time and the performance of the sampler is being evaluated.\n",
    "\n",
    "Code for the adaptation of the samplers used for these experiments can be found in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_basis(n_freqs,obs,TT):\n",
    "    X = np.zeros((n_freqs,len(obs)))\n",
    "    for i in range(1,n_freqs+1):\n",
    "        X[i-1,:] = (np.sqrt(2) / np.sqrt(TT)) * np.sin(i*np.pi*obs/TT)\n",
    "    return X\n",
    "\n",
    "def sin_DU(x,obs, TT = 50.0):\n",
    "    alpha = 0.7\n",
    "    dim = np.shape(x)[0]\n",
    "    x_recon = np.dot(BB_basis(dim,obs,TT).T,x)\n",
    "    DUx = ((alpha**2) * np.sin(x_recon)*np.cos(x_recon)) - ((alpha / 2)*np.sin(x_recon))\n",
    "    DUx_freqs = (TT/len(obs))*np.dot(BB_basis(dim,obs,TT),DUx)\n",
    "    return DUx_freqs\n",
    "\n",
    "def sin_DU_M(x,obs,TT=50.0,u = -np.pi,v = 3*np.pi):\n",
    "    alpha = 0.7\n",
    "    dim = np.shape(x)[0]\n",
    "    x_recon = np.dot(BB_basis(dim,obs,TT).T,x)\n",
    "    M = u + (obs/TT)*(v-u)\n",
    "    M = np.reshape(M,(len(obs),1))\n",
    "    DUx = ((alpha**2) * np.sin(x_recon + M)*np.cos(x_recon + M)) - ((alpha / 2)*np.sin(x_recon + M))\n",
    "    DUx_freqs = (TT/len(obs))*np.dot(BB_basis(dim,obs,TT),DUx)\n",
    "    return DUx_freqs\n",
    "\n",
    "def OU_DU(x,obs,TT=50.0,alpha = -5.0,beta = -1.0):\n",
    "    dim = np.shape(x)[0]\n",
    "    x_recon = np.dot(BB_basis(dim,obs,TT).T,x)\n",
    "    DUx = beta**2 * x_recon + alpha * beta\n",
    "    DUx_freqs = (TT/len(obs))*np.dot(BB_basis(dim,obs,TT),DUx)\n",
    "    return DUx_freqs\n",
    "\n",
    "def OU_DU_M(x,obs,TT=50.0,alpha = -5.0,beta = -1.0,u = -1.0,v = 2.0):\n",
    "    dim = np.shape(x)[0]\n",
    "    x_recon = np.dot(BB_basis(dim,obs,TT).T,x)\n",
    "    M = u + (obs/TT)*(v-u)\n",
    "    M = np.reshape(M,(len(obs),1))\n",
    "    DUx = beta**2 * (x_recon + M) + alpha * beta\n",
    "    DUx_freqs = (TT/len(obs))*np.dot(BB_basis(dim,obs,TT),DUx)\n",
    "    return DUx_freqs\n",
    "\n",
    "def interpolate_samples(X,inter_grid,original_grid):\n",
    "    \"\"\"\n",
    "        Arg:\n",
    "            X: (n_samples,n_points) data matrrix\n",
    "            inter_grid: the grid up to which the data shall be linearly interpolated\n",
    "            original_grid: the grid of points the trajectories were generated over\n",
    "        Return:\n",
    "            X: (n_samples,n_points) matrix of trajectories that have been linearly interpolated up to inter_grid\n",
    "    \"\"\"\n",
    "    Y = np.zeros((len(X),len(inter_grid)))\n",
    "    # for each trajectory linearly interpolate up to inter_grid\n",
    "    for i in range(len(X)):\n",
    "        Y[i,:] = np.interp(inter_grid,original_grid,X[i,:])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, set the discretisation parameter L, the perturbation parameter delta \n",
    "# and the terminal time TT \n",
    "# For all experimentss L = 6 as is used in Bierkins et al. \n",
    "paths = np.load('sin_paths/PDMP_paths/sin_PDMP_GoF_Data.npy')\n",
    "L = 6\n",
    "delta = 0.0\n",
    "TT = 50.0\n",
    "\n",
    "# Set up observation grid\n",
    "obs = np.linspace(0,TT,2**(L+1) + 1,endpoint=True)\n",
    "\n",
    "# Set the start (u) and end (v) values\n",
    "u = -np.pi\n",
    "v = 3*np.pi\n",
    "# u = -1\n",
    "# v = 2\n",
    "\n",
    "# n_inter_points = 2**(L+1) + 1\n",
    "# inter_grid = np.linspace(0,TT,n_inter_points,endpoint = True)\n",
    "# # paths = interpolate_samples(paths.T,inter_grid,obs).T\n",
    "paths = paths.T\n",
    "np.random.shuffle(paths)\n",
    "paths = paths.T\n",
    "\n",
    "# Set correct choice of DU\n",
    "DU_partial = partial(sin_DU_M,obs = obs, TT = TT,u=u,v=v)\n",
    "# DU_partial = partial(OU_DU_M,obs = obs, TT = TT,u=u,v=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of frequencies to use in numerical approximation of inner products\n",
    "# Here we use 100 meaning we are working in the space spanned by the first\n",
    "# 100 basis functions of Brownian bridge\n",
    "n_freqs = 100\n",
    "\n",
    "# Set the target covariance operator in matrix form with respect to \n",
    "# the specified number of basis elements, these are the eigenvalues \n",
    "# of Brownian bridge decomposition\n",
    "C = np.diag([(1/(i*np.pi/TT))**(2) for i in np.arange(1,n_freqs + 1)])\n",
    "\n",
    "# Set hyperparameters\n",
    "T_1 = np.eye(n_freqs)\n",
    "n_adjust_freqs = 50\n",
    "T_2 = np.eye(n_freqs)\n",
    "T_2[np.diag_indices(n_adjust_freqs)] = C[np.diag_indices(n_adjust_freqs)]**(-1)\n",
    "\n",
    "# Set median heuristic\n",
    "gamma = -1\n",
    "\n",
    "# Set test specification\n",
    "n_tests = 100\n",
    "n_bootstrap = 2000\n",
    "n_samples = 100\n",
    "\n",
    "# Set random seed\n",
    "rng_X = 1234\n",
    "\n",
    "# Store kernel and hyperparameter specifications\n",
    "kernel_list = [\"SE\",\"IMQ\"]\n",
    "T_list = [T_1,T_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-66ee997562d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Form the meann function M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Centre the paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'u' is not defined"
     ]
    }
   ],
   "source": [
    "# Form the meann function M \n",
    "M = u + (obs/TT)*(v-u)\n",
    "M = np.reshape(M,(len(obs),1))\n",
    "# Centre the paths\n",
    "paths = paths - M\n",
    "# Add the perturbation whose size is dictated by delta\n",
    "paths = paths + (delta * M)\n",
    "# Calculate the basis representation of the paths that is used for the KSD calculation\n",
    "path_freqs = (TT/len(obs))*np.dot(BB_basis(n_freqs,obs,TT),paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw1018/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5081013c8684483c9874013b6b558df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE  with T_ 1  n_samples  100  has power  0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a675edd8158a49649de800191e860823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE  with T_ 2  n_samples  100  has power  0.91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1369d5f4db2241f49f65d588a478e791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMQ  with T_ 1  n_samples  100  has power  0.92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e81c11874804ecdacaf62d73d6ed8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMQ  with T_ 2  n_samples  100  has power  0.92\n"
     ]
    }
   ],
   "source": [
    "for kernel in kernel_list:\n",
    "    for i in np.arange(len(T_list)):\n",
    "        T = T_list[i]\n",
    "        rej = 0\n",
    "        for t in tqdm_ntb(range(n_tests)):\n",
    "            my_KSD = KSD(C,T,DU = DU_partial,kernel_type = kernel)\n",
    "            data = path_freqs[:,t*n_samples:(t+1)*n_samples]\n",
    "            single_test = GoodnessOfFitTest(my_KSD,data)\n",
    "            _,_,pvalue = single_test.compute_pvalue(n_bootstrap)\n",
    "            rej += (pvalue < 0.05)\n",
    "        print(kernel,\" with T_\", i+1, \" n_samples \", n_samples, \" has power \",rej/n_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
